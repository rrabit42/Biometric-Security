{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "얼굴인식_진짜! (1).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "09iTWGikh5_a",
        "HcO-OJxb93tr",
        "UFercZZ295sL",
        "j3a1ctAc-Hku",
        "Q5TQbwyfjUop",
        "QOy6k7m7pNzc",
        "0w9_E23tWoA9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bffaL3xL9TcO",
        "outputId": "c69cbf44-4e7e-4ac1-ac62-164902f8184f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFjnFWw0-N7o"
      },
      "source": [
        "#필요한 라이브러리 불러오기\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as pylab\n",
        "from sklearn.metrics import pairwise_distances_argmin\n",
        "from skimage.io import imread\n",
        "from sklearn.utils import shuffle\n",
        "from skimage import img_as_float\n",
        "\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras.utils import np_utils  # to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from keras import optimizers\n",
        "import tensorflow as tf"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-JFch0J19uUb"
      },
      "source": [
        "W = 244\n",
        "H = 244\n",
        "F = 1\n",
        "Nout = 351\n",
        "\n",
        "epochs=100\n",
        "batch_size=100"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FC-aWZCoEGyC"
      },
      "source": [
        "# 탐지 결과를 위한 함수들"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sy-zVrA9y4Z"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI5nn-2DakKn"
      },
      "source": [
        "# 추후에 쓰면 좋을 것"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bek0pi0kEJoE"
      },
      "source": [
        "# plot 그래프"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er1HmJxp9Xow"
      },
      "source": [
        "# 학습 결과 분석을 위한 그래프 구현\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_acc(history, title=None):\n",
        "  # summarize history for accuracy\n",
        "  if not isinstance(history, dict):\n",
        "    history = history.history\n",
        "  plt.plot(history['accuracy'])\n",
        "  plt.plot(history['val_accuracy'])\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Verification'], loc=0)   # 두 선의 이름(Train, Test) 표시\n",
        "\n",
        "def plot_loss(history, title=None):\n",
        "  # summarize history for loss\n",
        "  if not isinstance(history, dict):\n",
        "    history = history.history\n",
        "  plt.plot(history['loss'])             # 학습 데이터로 구한 손실값\n",
        "  plt.plot(history['val_loss'])         # 검증 데이터로 구한 손실값\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.ylabel('Loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.legend(['Training', 'Verification'], loc=0)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b4NXkfYlELRJ"
      },
      "source": [
        "# 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qhpfKkrE9o6U"
      },
      "source": [
        "train_dir = './drive/MyDrive/02_face_training'\n",
        "filenames = os.listdir(train_dir)\n",
        "\n",
        "faces = []\n",
        "labels = []\n",
        "\n",
        "for filename in filenames[:-1]:\n",
        "    label = filename[0:4]\n",
        "    image = cv2.imread(train_dir+'/'+filename, 0)\n",
        "    # image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    # image = np.array(image).reshape((-1, W, H, 3))\n",
        "    image = cv2.resize(image, (W,H))\n",
        "    faces.append(image)\n",
        "    labels.append(int(label))\n",
        "\n",
        "faces = np.asarray(faces)\n",
        "faces = faces.astype('float32')\n",
        "\n",
        "# 1~9의 숫자로 된 출력값을 이진수(0/1)로 표현되는 벡터로 바꿈 (더 효율적)\n",
        "# 원핫인코딩\n",
        "labels = np_utils.to_categorical(labels, num_classes = Nout)\n",
        "\n",
        "faces = faces.reshape(-1,W,H,1)\n",
        "faces = faces / 255.\n",
        "\n",
        "train_X, test_X, train_Y, test_Y = train_test_split(faces, labels, test_size=0.2, random_state=13)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TctzQqgRkmDi",
        "outputId": "ad2d8f92-3959-4d12-d02a-fa557f3f6faa"
      },
      "source": [
        "faces.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1049, 244, 244, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8nG_HaLkqbw",
        "outputId": "b2c0c427-1b31-4078-b3b9-36bf2749657d"
      },
      "source": [
        "labels.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1049, 351)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09iTWGikh5_a"
      },
      "source": [
        "# 모델 시도 0 : 오토 인코더"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "1Skm_SWmh38R",
        "outputId": "8fd02ec3-952a-4c83-8eed-6df32c831456"
      },
      "source": [
        "model = models.Sequential([\n",
        "  # Encoder\n",
        "  layers.Conv2D(32, (2,2), activation='relu', padding=\"same\", input_shape=(W, H, F)),\n",
        "  layers.MaxPooling2D(pool_size=(1,1)),\n",
        "  # layers.Conv2D(32, (2,2), activation='relu', padding=\"same\"),\n",
        "  # layers.MaxPooling2D(pool_size=(1,1)),\n",
        "  # layers.Conv2D(32, (2,2), activation='relu', padding=\"same\"),\n",
        "  # Decoder\n",
        "  layers.Conv2D(32, (2,2), activation='relu', padding=\"same\"),\n",
        "  layers.UpSampling2D((2,2)),\n",
        "  layers.Conv2D(32, (2,2), activation='relu', padding=\"same\"),\n",
        "  layers.UpSampling2D((1,1)),\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(Nout, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy', precision, recall, f1score])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ResourceExhaustedError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-fc80219ea3a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUpSampling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'softmax'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m ])\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, layers, name)\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mlayers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    221\u001b[0m       \u001b[0;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m       \u001b[0;31m# refresh its output.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m       \u001b[0moutput_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSINGLE_LAYER_OUTPUT_ERROR_MSG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    860\u001b[0m           \u001b[0;31m# overridden).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 862\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    863\u001b[0m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2708\u001b[0m         \u001b[0;31m# operations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2709\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaybe_init_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2710\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2711\u001b[0m       \u001b[0;31m# We must set also ensure that the layer is marked as built, and the build\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2712\u001b[0m       \u001b[0;31m# shape is stored since user defined build functions may not be calling\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/core.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1192\u001b[0;31m         trainable=True)\n\u001b[0m\u001b[1;32m   1193\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m       self.bias = self.add_weight(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, **kwargs)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m         caching_device=caching_device)\n\u001b[0m\u001b[1;32m    640\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m       \u001b[0;31m# TODO(fchollet): in the future, this should be handled at the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    808\u001b[0m         \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m         \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 810\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    811\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mmake_variable\u001b[0;34m(name, shape, dtype, initializer, trainable, caching_device, validate_shape, constraint, use_resource, collections, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    140\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m       \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m       shape=variable_shape if variable_shape else None)\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    258\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariableV1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v1_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    261\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_v1_call\u001b[0;34m(cls, initial_value, trainable, collections, validate_shape, caching_device, name, variable_def, dtype, expected_shape, import_scope, constraint, use_resource, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m   def _variable_v2_call(cls,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m                         shape=None):\n\u001b[1;32m    198\u001b[0m     \u001b[0;34m\"\"\"Call on Variable class. Useful to force the signature.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m     \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_variable_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetter\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creator_stack\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m       \u001b[0mprevious_getter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_make_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprevious_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mdefault_variable_creator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   2616\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2617\u001b[0m         \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2618\u001b[0;31m         shape=shape)\n\u001b[0m\u001b[1;32m   2619\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2620\u001b[0m     return variables.RefVariable(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_v2_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 264\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, collections, validate_shape, caching_device, name, dtype, variable_def, import_scope, constraint, distribute_strategy, synchronization, aggregation, shape)\u001b[0m\n\u001b[1;32m   1583\u001b[0m           \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m           \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m           distribute_strategy=distribute_strategy)\n\u001b[0m\u001b[1;32m   1586\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m   def _init_from_args(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001b[0m in \u001b[0;36m_init_from_args\u001b[0;34m(self, initial_value, trainable, collections, caching_device, name, dtype, constraint, synchronization, aggregation, distribute_strategy, shape)\u001b[0m\n\u001b[1;32m   1710\u001b[0m           \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Initializer\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1711\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minit_from_fn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1712\u001b[0;31m               \u001b[0minitial_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitial_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1713\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrackable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCheckpointInitialValue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1714\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_initialize_trackable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/initializers/initializers_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m     \"\"\"\n\u001b[1;32m    409\u001b[0m     return super(VarianceScaling, self).__call__(\n\u001b[0;32m--> 410\u001b[0;31m         shape, dtype=_get_dtype(dtype), **kwargs)\n\u001b[0m\u001b[1;32m    411\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, shape, dtype, **kwargs)\u001b[0m\n\u001b[1;32m    598\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m       \u001b[0mlimit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_random_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/init_ops_v2.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   1080\u001b[0m       \u001b[0mop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_uniform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m     return op(\n\u001b[0;32m-> 1082\u001b[0;31m         shape=shape, minval=minval, maxval=maxval, dtype=dtype, seed=self.seed)\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstddev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, minval, maxval, dtype, seed, name)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m       result = gen_random_ops.random_uniform(\n\u001b[0;32m--> 303\u001b[0;31m           shape, dtype, seed=seed1, seed2=seed2)\n\u001b[0m\u001b[1;32m    304\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mminval_is_zero\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmaxval_is_one\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_random_ops.py\u001b[0m in \u001b[0;36mrandom_uniform\u001b[0;34m(shape, dtype, seed, seed2, name)\u001b[0m\n\u001b[1;32m    719\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 721\u001b[0;31m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    722\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    723\u001b[0m       \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6860\u001b[0m   \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\" name: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6861\u001b[0m   \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6862\u001b[0;31m   \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6863\u001b[0m   \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/six.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(value, from_value)\u001b[0m\n",
            "\u001b[0;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[2654208,351] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc [Op:RandomUniform]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aH3KcuAgkKno"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcO-OJxb93tr"
      },
      "source": [
        "# 모델 시도 1 : CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anx9X9P693VB",
        "outputId": "64c5d08e-4d24-45a2-d90a-921ff204663a"
      },
      "source": [
        "rate = 0.5\n",
        "\n",
        "model = models.Sequential([\n",
        "  layers.Conv2D(64, (3,3), activation='relu', padding=\"same\", input_shape=(W, H, F)),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(rate),\n",
        "\n",
        "  layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "  layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "  layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  layers.BatchNormalization(),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dropout(rate),\n",
        "  layers.Dense(512, activation='relu'),\n",
        "  layers.Dropout(rate),\n",
        "  layers.Dense(Nout, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_12 (Conv2D)           (None, 144, 144, 64)      640       \n",
            "_________________________________________________________________\n",
            "batch_normalization_16 (Batc (None, 144, 144, 64)      256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_12 (MaxPooling (None, 72, 72, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 72, 72, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_13 (Conv2D)           (None, 70, 70, 64)        36928     \n",
            "_________________________________________________________________\n",
            "batch_normalization_17 (Batc (None, 70, 70, 64)        256       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_13 (MaxPooling (None, 35, 35, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_14 (Conv2D)           (None, 33, 33, 128)       73856     \n",
            "_________________________________________________________________\n",
            "batch_normalization_18 (Batc (None, 33, 33, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_14 (MaxPooling (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_15 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "batch_normalization_19 (Batc (None, 14, 14, 128)       512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_15 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_12 (Dense)             (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_13 (Dense)             (None, 351)               180063    \n",
            "=================================================================\n",
            "Total params: 3,652,383\n",
            "Trainable params: 3,651,615\n",
            "Non-trainable params: 768\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IcMgxOBT9-t1"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy', precision, recall, f1score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFercZZ295sL"
      },
      "source": [
        "# 모델 시도 2 : CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uJVkon-a9vPg",
        "outputId": "3ee76d91-9c5d-4432-fc69-7a95c824365c"
      },
      "source": [
        "model = models.Sequential([\n",
        "  layers.Conv2D(64, (3,3), activation='relu', padding=\"same\", input_shape=(W, H, F)),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(0.25),\n",
        "\n",
        "  layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(0.25),\n",
        "\n",
        "  layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(0.25),\n",
        "\n",
        "  layers.Conv2D(128, (3,3), activation='relu'),\n",
        "  layers.MaxPooling2D(pool_size=(2,2)),\n",
        "  layers.Dropout(0.25),\n",
        "\n",
        "  layers.Flatten(),\n",
        "  layers.Dense(512, activation='relu', kernel_initializer = 'glorot_uniform', kernel_regularizer=tf.keras.regularizers.l2(0)),\n",
        "  layers.Dropout(0.5),\n",
        "  layers.Dense(Nout, activation='softmax')\n",
        "])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_8 (Conv2D)            (None, 144, 144, 64)      640       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 72, 72, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 72, 72, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 70, 70, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 35, 35, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 35, 35, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 33, 33, 128)       73856     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_10 (MaxPooling (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_11 (Conv2D)           (None, 14, 14, 128)       147584    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_11 (MaxPooling (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 7, 7, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               3211776   \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 351)               180063    \n",
            "=================================================================\n",
            "Total params: 3,650,847\n",
            "Trainable params: 3,650,847\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19K1Y1zN-Fte"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy', precision, recall, f1score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j3a1ctAc-Hku"
      },
      "source": [
        "# 모델 시도 3 : Resnet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AdXSSLLS-E0G",
        "outputId": "49bdd533-ac70-4680-b973-7b8ae971788c"
      },
      "source": [
        "# 모델 출처: https://rarena.tistory.com/entry/keras-%ED%8A%B9%EC%A0%95-%EB%AA%A8%EB%8D%B8%EB%A1%9C%EB%93%9C%ED%95%98%EC%97%AC-%EB%82%B4-%EB%A0%88%EC%9D%B4%EC%96%B4\n",
        "\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input, decode_predictions\n",
        "# from tensorflow.keras.applications import ResNet34, preprocess_input, decode_predictions\n",
        "\n",
        "input = layers.Input(shape=(W,H,F))\n",
        "model = ResNet50(input_tensor=input, include_top=False, weights=None, pooling='max')\n",
        "\n",
        "x = model.output\n",
        "x = layers.Dense(512)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dense(Nout, activation='softmax', name='softmax')(x)\n",
        "model = models.Model(model.input, x)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 244, 244, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv1_pad (ZeroPadding2D)       (None, 250, 250, 3)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv1_conv (Conv2D)             (None, 122, 122, 64) 9472        conv1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv1_bn (BatchNormalization)   (None, 122, 122, 64) 256         conv1_conv[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv1_relu (Activation)         (None, 122, 122, 64) 0           conv1_bn[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pad (ZeroPadding2D)       (None, 124, 124, 64) 0           conv1_relu[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "pool1_pool (MaxPooling2D)       (None, 61, 61, 64)   0           pool1_pad[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_conv (Conv2D)    (None, 61, 61, 64)   4160        pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_bn (BatchNormali (None, 61, 61, 64)   256         conv2_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_1_relu (Activation (None, 61, 61, 64)   0           conv2_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_conv (Conv2D)    (None, 61, 61, 64)   36928       conv2_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_bn (BatchNormali (None, 61, 61, 64)   256         conv2_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_2_relu (Activation (None, 61, 61, 64)   0           conv2_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_conv (Conv2D)    (None, 61, 61, 256)  16640       pool1_pool[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_conv (Conv2D)    (None, 61, 61, 256)  16640       conv2_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_0_bn (BatchNormali (None, 61, 61, 256)  1024        conv2_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_3_bn (BatchNormali (None, 61, 61, 256)  1024        conv2_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_add (Add)          (None, 61, 61, 256)  0           conv2_block1_0_bn[0][0]          \n",
            "                                                                 conv2_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block1_out (Activation)   (None, 61, 61, 256)  0           conv2_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_conv (Conv2D)    (None, 61, 61, 64)   16448       conv2_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_bn (BatchNormali (None, 61, 61, 64)   256         conv2_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_1_relu (Activation (None, 61, 61, 64)   0           conv2_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_conv (Conv2D)    (None, 61, 61, 64)   36928       conv2_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_bn (BatchNormali (None, 61, 61, 64)   256         conv2_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_2_relu (Activation (None, 61, 61, 64)   0           conv2_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_conv (Conv2D)    (None, 61, 61, 256)  16640       conv2_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_3_bn (BatchNormali (None, 61, 61, 256)  1024        conv2_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_add (Add)          (None, 61, 61, 256)  0           conv2_block1_out[0][0]           \n",
            "                                                                 conv2_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block2_out (Activation)   (None, 61, 61, 256)  0           conv2_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_conv (Conv2D)    (None, 61, 61, 64)   16448       conv2_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_bn (BatchNormali (None, 61, 61, 64)   256         conv2_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_1_relu (Activation (None, 61, 61, 64)   0           conv2_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_conv (Conv2D)    (None, 61, 61, 64)   36928       conv2_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_bn (BatchNormali (None, 61, 61, 64)   256         conv2_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_2_relu (Activation (None, 61, 61, 64)   0           conv2_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_conv (Conv2D)    (None, 61, 61, 256)  16640       conv2_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_3_bn (BatchNormali (None, 61, 61, 256)  1024        conv2_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_add (Add)          (None, 61, 61, 256)  0           conv2_block2_out[0][0]           \n",
            "                                                                 conv2_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv2_block3_out (Activation)   (None, 61, 61, 256)  0           conv2_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_conv (Conv2D)    (None, 31, 31, 128)  32896       conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_bn (BatchNormali (None, 31, 31, 128)  512         conv3_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_1_relu (Activation (None, 31, 31, 128)  0           conv3_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_conv (Conv2D)    (None, 31, 31, 128)  147584      conv3_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_bn (BatchNormali (None, 31, 31, 128)  512         conv3_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_2_relu (Activation (None, 31, 31, 128)  0           conv3_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_conv (Conv2D)    (None, 31, 31, 512)  131584      conv2_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_conv (Conv2D)    (None, 31, 31, 512)  66048       conv3_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_0_bn (BatchNormali (None, 31, 31, 512)  2048        conv3_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_3_bn (BatchNormali (None, 31, 31, 512)  2048        conv3_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_add (Add)          (None, 31, 31, 512)  0           conv3_block1_0_bn[0][0]          \n",
            "                                                                 conv3_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block1_out (Activation)   (None, 31, 31, 512)  0           conv3_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_conv (Conv2D)    (None, 31, 31, 128)  65664       conv3_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_bn (BatchNormali (None, 31, 31, 128)  512         conv3_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_1_relu (Activation (None, 31, 31, 128)  0           conv3_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_conv (Conv2D)    (None, 31, 31, 128)  147584      conv3_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_bn (BatchNormali (None, 31, 31, 128)  512         conv3_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_2_relu (Activation (None, 31, 31, 128)  0           conv3_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_conv (Conv2D)    (None, 31, 31, 512)  66048       conv3_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_3_bn (BatchNormali (None, 31, 31, 512)  2048        conv3_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_add (Add)          (None, 31, 31, 512)  0           conv3_block1_out[0][0]           \n",
            "                                                                 conv3_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block2_out (Activation)   (None, 31, 31, 512)  0           conv3_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_conv (Conv2D)    (None, 31, 31, 128)  65664       conv3_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_bn (BatchNormali (None, 31, 31, 128)  512         conv3_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_1_relu (Activation (None, 31, 31, 128)  0           conv3_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_conv (Conv2D)    (None, 31, 31, 128)  147584      conv3_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_bn (BatchNormali (None, 31, 31, 128)  512         conv3_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_2_relu (Activation (None, 31, 31, 128)  0           conv3_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_conv (Conv2D)    (None, 31, 31, 512)  66048       conv3_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_3_bn (BatchNormali (None, 31, 31, 512)  2048        conv3_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_add (Add)          (None, 31, 31, 512)  0           conv3_block2_out[0][0]           \n",
            "                                                                 conv3_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block3_out (Activation)   (None, 31, 31, 512)  0           conv3_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_conv (Conv2D)    (None, 31, 31, 128)  65664       conv3_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_bn (BatchNormali (None, 31, 31, 128)  512         conv3_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_1_relu (Activation (None, 31, 31, 128)  0           conv3_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_conv (Conv2D)    (None, 31, 31, 128)  147584      conv3_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_bn (BatchNormali (None, 31, 31, 128)  512         conv3_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_2_relu (Activation (None, 31, 31, 128)  0           conv3_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_conv (Conv2D)    (None, 31, 31, 512)  66048       conv3_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_3_bn (BatchNormali (None, 31, 31, 512)  2048        conv3_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_add (Add)          (None, 31, 31, 512)  0           conv3_block3_out[0][0]           \n",
            "                                                                 conv3_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv3_block4_out (Activation)   (None, 31, 31, 512)  0           conv3_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_conv (Conv2D)    (None, 16, 16, 256)  131328      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_1_relu (Activation (None, 16, 16, 256)  0           conv4_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_2_relu (Activation (None, 16, 16, 256)  0           conv4_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_conv (Conv2D)    (None, 16, 16, 1024) 525312      conv3_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_0_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_0_bn[0][0]          \n",
            "                                                                 conv4_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block1_out (Activation)   (None, 16, 16, 1024) 0           conv4_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_1_relu (Activation (None, 16, 16, 256)  0           conv4_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_2_relu (Activation (None, 16, 16, 256)  0           conv4_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_add (Add)          (None, 16, 16, 1024) 0           conv4_block1_out[0][0]           \n",
            "                                                                 conv4_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block2_out (Activation)   (None, 16, 16, 1024) 0           conv4_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_1_relu (Activation (None, 16, 16, 256)  0           conv4_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_2_relu (Activation (None, 16, 16, 256)  0           conv4_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_add (Add)          (None, 16, 16, 1024) 0           conv4_block2_out[0][0]           \n",
            "                                                                 conv4_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block3_out (Activation)   (None, 16, 16, 1024) 0           conv4_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_1_relu (Activation (None, 16, 16, 256)  0           conv4_block4_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block4_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block4_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_2_relu (Activation (None, 16, 16, 256)  0           conv4_block4_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_add (Add)          (None, 16, 16, 1024) 0           conv4_block3_out[0][0]           \n",
            "                                                                 conv4_block4_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block4_out (Activation)   (None, 16, 16, 1024) 0           conv4_block4_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block4_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_1_relu (Activation (None, 16, 16, 256)  0           conv4_block5_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block5_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block5_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_2_relu (Activation (None, 16, 16, 256)  0           conv4_block5_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_add (Add)          (None, 16, 16, 1024) 0           conv4_block4_out[0][0]           \n",
            "                                                                 conv4_block5_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block5_out (Activation)   (None, 16, 16, 1024) 0           conv4_block5_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_conv (Conv2D)    (None, 16, 16, 256)  262400      conv4_block5_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_1_relu (Activation (None, 16, 16, 256)  0           conv4_block6_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_conv (Conv2D)    (None, 16, 16, 256)  590080      conv4_block6_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_bn (BatchNormali (None, 16, 16, 256)  1024        conv4_block6_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_2_relu (Activation (None, 16, 16, 256)  0           conv4_block6_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_conv (Conv2D)    (None, 16, 16, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_3_bn (BatchNormali (None, 16, 16, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_add (Add)          (None, 16, 16, 1024) 0           conv4_block5_out[0][0]           \n",
            "                                                                 conv4_block6_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv4_block6_out (Activation)   (None, 16, 16, 1024) 0           conv4_block6_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_conv (Conv2D)    (None, 8, 8, 512)    524800      conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_1_relu (Activation (None, 8, 8, 512)    0           conv5_block1_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block1_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_2_relu (Activation (None, 8, 8, 512)    0           conv5_block1_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_conv (Conv2D)    (None, 8, 8, 2048)   2099200     conv4_block6_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_0_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_0_bn[0][0]          \n",
            "                                                                 conv5_block1_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block1_out (Activation)   (None, 8, 8, 2048)   0           conv5_block1_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block1_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_1_relu (Activation (None, 8, 8, 512)    0           conv5_block2_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block2_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_2_relu (Activation (None, 8, 8, 512)    0           conv5_block2_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_add (Add)          (None, 8, 8, 2048)   0           conv5_block1_out[0][0]           \n",
            "                                                                 conv5_block2_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block2_out (Activation)   (None, 8, 8, 2048)   0           conv5_block2_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_conv (Conv2D)    (None, 8, 8, 512)    1049088     conv5_block2_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_1_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_1_relu (Activation (None, 8, 8, 512)    0           conv5_block3_1_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_conv (Conv2D)    (None, 8, 8, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_bn (BatchNormali (None, 8, 8, 512)    2048        conv5_block3_2_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_2_relu (Activation (None, 8, 8, 512)    0           conv5_block3_2_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_conv (Conv2D)    (None, 8, 8, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_3_bn (BatchNormali (None, 8, 8, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_add (Add)          (None, 8, 8, 2048)   0           conv5_block2_out[0][0]           \n",
            "                                                                 conv5_block3_3_bn[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "conv5_block3_out (Activation)   (None, 8, 8, 2048)   0           conv5_block3_add[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "max_pool (GlobalMaxPooling2D)   (None, 2048)         0           conv5_block3_out[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 512)          1049088     max_pool[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 512)          2048        dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 512)          0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "softmax (Dense)                 (None, 351)          180063      activation[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 24,818,911\n",
            "Trainable params: 24,764,767\n",
            "Non-trainable params: 54,144\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNmv5Dhu-qpQ"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy', precision, recall, f1score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3JoTtWM-gmd"
      },
      "source": [
        "# 모델 시도4 : Resnet 직접 함수 구현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bd48UERf-Exp"
      },
      "source": [
        "# 모델 출처: https://eremo2002.tistory.com/76\n",
        "\n",
        "from keras import models, layers\n",
        "from keras import Input\n",
        "from keras.models import Model, load_model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras import optimizers, initializers, regularizers, metrics\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from keras.layers import BatchNormalization, Conv2D, Activation, Dense, GlobalAveragePooling2D, MaxPooling2D, ZeroPadding2D, Add\n",
        " \n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        " \n",
        "def conv1_layer(x):    \n",
        "    x = ZeroPadding2D(padding=(3, 3))(x)\n",
        "    x = Conv2D(64, (7, 7), strides=(2, 2))(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = ZeroPadding2D(padding=(1,1))(x)\n",
        " \n",
        "    return x   \n",
        " \n",
        "\n",
        "def conv2_layer(x):         \n",
        "    x = MaxPooling2D((3, 3), 2)(x)     \n",
        " \n",
        "    shortcut = x\n",
        " \n",
        "    for i in range(2):\n",
        "        if (i == 0):\n",
        "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "            \n",
        "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        " \n",
        "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            shortcut = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(shortcut)            \n",
        "            x = BatchNormalization()(x)\n",
        "            shortcut = BatchNormalization()(shortcut)\n",
        " \n",
        "            x = Add()([x, shortcut])\n",
        "            x = Activation('relu')(x)\n",
        "            \n",
        "            shortcut = x\n",
        " \n",
        "        else:\n",
        "            x = Conv2D(64, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "            \n",
        "            x = Conv2D(64, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        " \n",
        "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)            \n",
        " \n",
        "            x = Add()([x, shortcut])   \n",
        "            x = Activation('relu')(x)  \n",
        " \n",
        "            shortcut = x        \n",
        "    \n",
        "    return x\n",
        " \n",
        " \n",
        " \n",
        "def conv3_layer(x):        \n",
        "    shortcut = x    \n",
        "    \n",
        "    for i in range(2):     \n",
        "        if(i == 0):            \n",
        "            x = Conv2D(128, (1, 1), strides=(2, 2), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)        \n",
        "            \n",
        "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)  \n",
        " \n",
        "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            shortcut = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
        "            x = BatchNormalization()(x)\n",
        "            shortcut = BatchNormalization()(shortcut)            \n",
        " \n",
        "            x = Add()([x, shortcut])    \n",
        "            x = Activation('relu')(x)    \n",
        " \n",
        "            shortcut = x              \n",
        "        \n",
        "        else:\n",
        "            x = Conv2D(128, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "            \n",
        "            x = Conv2D(128, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        " \n",
        "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)            \n",
        " \n",
        "            x = Add()([x, shortcut])     \n",
        "            x = Activation('relu')(x)\n",
        " \n",
        "            shortcut = x      \n",
        "            \n",
        "    return x\n",
        " \n",
        " \n",
        " \n",
        "def conv4_layer(x):\n",
        "    shortcut = x        \n",
        "  \n",
        "    for i in range(2):     \n",
        "        if(i == 0):            \n",
        "            x = Conv2D(256, (1, 1), strides=(2, 2), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)        \n",
        "            \n",
        "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)  \n",
        " \n",
        "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            shortcut = Conv2D(1024, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
        "            x = BatchNormalization()(x)\n",
        "            shortcut = BatchNormalization()(shortcut)\n",
        " \n",
        "            x = Add()([x, shortcut]) \n",
        "            x = Activation('relu')(x)\n",
        " \n",
        "            shortcut = x               \n",
        "        \n",
        "        else:\n",
        "            x = Conv2D(256, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "            \n",
        "            x = Conv2D(256, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        " \n",
        "            x = Conv2D(1024, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)            \n",
        " \n",
        "            x = Add()([x, shortcut])    \n",
        "            x = Activation('relu')(x)\n",
        " \n",
        "            shortcut = x      \n",
        " \n",
        "    return x\n",
        " \n",
        " \n",
        " \n",
        "def conv5_layer(x):\n",
        "    shortcut = x    \n",
        "  \n",
        "    for i in range(2):     \n",
        "        if(i == 0):            \n",
        "            x = Conv2D(512, (1, 1), strides=(2, 2), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)        \n",
        "            \n",
        "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)  \n",
        " \n",
        "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            shortcut = Conv2D(2048, (1, 1), strides=(2, 2), padding='valid')(shortcut)\n",
        "            x = BatchNormalization()(x)\n",
        "            shortcut = BatchNormalization()(shortcut)            \n",
        " \n",
        "            x = Add()([x, shortcut])  \n",
        "            x = Activation('relu')(x)      \n",
        " \n",
        "            shortcut = x               \n",
        "        \n",
        "        else:\n",
        "            x = Conv2D(512, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        "            \n",
        "            x = Conv2D(512, (3, 3), strides=(1, 1), padding='same')(x)\n",
        "            x = BatchNormalization()(x)\n",
        "            x = Activation('relu')(x)\n",
        " \n",
        "            x = Conv2D(2048, (1, 1), strides=(1, 1), padding='valid')(x)\n",
        "            x = BatchNormalization()(x)           \n",
        "            \n",
        "            x = Add()([x, shortcut]) \n",
        "            x = Activation('relu')(x)       \n",
        " \n",
        "            shortcut = x                  \n",
        " \n",
        "    return x\n"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8rwxOr4-kBO"
      },
      "source": [
        "from keras.optimizers import Adam\n",
        "def ResNet(W, H, F, Nout):\n",
        "  input_tensor = Input(shape=(W, H, F), dtype='float32', name='input')\n",
        "  x = conv1_layer(input_tensor)\n",
        "  x = conv2_layer(x)\n",
        "  x = conv3_layer(x)\n",
        "  x = conv4_layer(x)\n",
        "  x = conv5_layer(x)\n",
        "  x = GlobalAveragePooling2D()(x)\n",
        "  output_tensor = Dense(Nout, activation='softmax', kernel_initializer='glorot_uniform')(x)\n",
        "  \n",
        "  model = Model(input_tensor, output_tensor)\n",
        "\n",
        "  model.compile(loss='categorical_crossentropy',\n",
        "                optimizer='adam',\n",
        "                metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5TQbwyfjUop"
      },
      "source": [
        "# 모델 시도 5 : VGG16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmM7ZwKwjTZr"
      },
      "source": [
        "from tensorflow.python.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.layers import Conv2D, MaxPooling2D, Flatten\n",
        "from tensorflow.python.keras.layers import Dense, Dropout, Input\n",
        "from tensorflow.python.keras.models import Model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GvR7hKIUjdzw"
      },
      "source": [
        "input_tensor = Input(shape=(W,H,F))\n",
        "model = VGG16(weights='imagenet', include_top=False, input_tensor = input_tensor)\n",
        "\n",
        "# 모델 Layer 데이터화\n",
        "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
        "\n",
        "# Layer 추가\n",
        "x = layer_dict['block5_pool'].output\n",
        "# Cov2D Layer +\n",
        "x = Conv2D(filters = 64, kernel_size=(3, 3), activation='relu')(x)\n",
        "# MaxPooling2D Layer +\n",
        "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "# Flatten Layer +\n",
        "x = Flatten()(x)\n",
        "# FC Layer +\n",
        "x = Dense(2048, activation='relu', kernel_initializer = 'glorot_uniform', kernel_regularizer=tf.keras.regularizers.l2(0))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(1024, activation='relu', kernel_initializer = 'glorot_uniform', kernel_regularizer=tf.keras.regularizers.l2(0))(x)\n",
        "x = Dropout(0.5)(x)\n",
        "x = Dense(Nout, activation='softmax')(x)\n",
        "\n",
        "# new model 정의\n",
        "model = Model(inputs = model.input, outputs = x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDCMIjK-jzye",
        "outputId": "be67d632-9a6b-49fe-bc4d-c57317970734"
      },
      "source": [
        "# CNN Pre-trained 가중치를 그대로 사용할때\n",
        "for layer in model.layers[:19] :\n",
        "    layer.trainable = False\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 컴파일 옵션\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy', precision, recall, f1score])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_12 (InputLayer)        [(None, 244, 244, 3)]     0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 244, 244, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 244, 244, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 122, 122, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 122, 122, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 122, 122, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 61, 61, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 61, 61, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 61, 61, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 61, 61, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 30, 30, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 30, 30, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 30, 30, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 30, 30, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_31 (Conv2D)           (None, 5, 5, 64)          294976    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_31 (MaxPooling (None, 2, 2, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_16 (Flatten)         (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 2048)              526336    \n",
            "_________________________________________________________________\n",
            "dropout_46 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_42 (Dense)             (None, 1024)              2098176   \n",
            "_________________________________________________________________\n",
            "dropout_47 (Dropout)         (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_43 (Dense)             (None, 351)               359775    \n",
            "=================================================================\n",
            "Total params: 17,993,951\n",
            "Trainable params: 3,279,263\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QOy6k7m7pNzc"
      },
      "source": [
        "# 모델 시도 6 : VGG16 다른거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQhgi9MspNBN"
      },
      "source": [
        "transfer_model = VGG16(weights='imagenet', include_top=False, input_shape=(W, H, F))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wqAqbAb_pXUx"
      },
      "source": [
        "transfer_model.trainable=False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MmyLofiXpaq3"
      },
      "source": [
        "model = models.Sequential([\n",
        "    transfer_model, \n",
        "    Flatten(), \n",
        "    Dense(64, activation='relu'), \n",
        "    Dense(Nout, 'softmax')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FnjwU2HgphV9"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy', precision, recall, f1score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0w9_E23tWoA9"
      },
      "source": [
        "# 모델 시도 7 : resnet 종류별"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NTw_DEUbkFd"
      },
      "source": [
        "NUM_CLASSES = Nout"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxGyrt5zcT7f"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "class BasicBlock(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, filter_num, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3, 3),\n",
        "                                            strides=stride,\n",
        "                                            padding=\"same\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3, 3),\n",
        "                                            strides=1,\n",
        "                                            padding=\"same\")\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        if stride != 1:\n",
        "            self.downsample = tf.keras.Sequential()\n",
        "            self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                                       kernel_size=(1, 1),\n",
        "                                                       strides=stride))\n",
        "            self.downsample.add(tf.keras.layers.BatchNormalization())\n",
        "        else:\n",
        "            self.downsample = lambda x: x\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        residual = self.downsample(inputs)\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "\n",
        "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class BottleNeck(tf.keras.layers.Layer):\n",
        "    def __init__(self, filter_num, stride=1):\n",
        "        super(BottleNeck, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(1, 1),\n",
        "                                            strides=1,\n",
        "                                            padding='same')\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv2 = tf.keras.layers.Conv2D(filters=filter_num,\n",
        "                                            kernel_size=(3, 3),\n",
        "                                            strides=stride,\n",
        "                                            padding='same')\n",
        "        self.bn2 = tf.keras.layers.BatchNormalization()\n",
        "        self.conv3 = tf.keras.layers.Conv2D(filters=filter_num * 4,\n",
        "                                            kernel_size=(1, 1),\n",
        "                                            strides=1,\n",
        "                                            padding='same')\n",
        "        self.bn3 = tf.keras.layers.BatchNormalization()\n",
        "\n",
        "        self.downsample = tf.keras.Sequential()\n",
        "        self.downsample.add(tf.keras.layers.Conv2D(filters=filter_num * 4,\n",
        "                                                   kernel_size=(1, 1),\n",
        "                                                   strides=stride))\n",
        "        self.downsample.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    def call(self, inputs, training=None, **kwargs):\n",
        "        residual = self.downsample(inputs)\n",
        "\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x, training=training)\n",
        "\n",
        "        output = tf.nn.relu(tf.keras.layers.add([residual, x]))\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "def make_basic_block_layer(filter_num, blocks, stride=1):\n",
        "    res_block = tf.keras.Sequential()\n",
        "    res_block.add(BasicBlock(filter_num, stride=stride))\n",
        "\n",
        "    for _ in range(1, blocks):\n",
        "        res_block.add(BasicBlock(filter_num, stride=1))\n",
        "\n",
        "    return res_block\n",
        "\n",
        "\n",
        "def make_bottleneck_layer(filter_num, blocks, stride=1):\n",
        "    res_block = tf.keras.Sequential()\n",
        "    res_block.add(BottleNeck(filter_num, stride=stride))\n",
        "\n",
        "    for _ in range(1, blocks):\n",
        "        res_block.add(BottleNeck(filter_num, stride=1))\n",
        "\n",
        "    return res_block"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT7SZPNCWtGM"
      },
      "source": [
        "class ResNetTypeI(tf.keras.Model):\n",
        "    def __init__(self, layer_params):\n",
        "        super(ResNetTypeI, self).__init__()\n",
        "\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
        "                                            kernel_size=(7, 7),\n",
        "                                            strides=2,\n",
        "                                            padding=\"same\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                               strides=2,\n",
        "                                               padding=\"same\")\n",
        "\n",
        "        self.layer1 = make_basic_block_layer(filter_num=64,\n",
        "                                             blocks=layer_params[0])\n",
        "        self.layer2 = make_basic_block_layer(filter_num=128,\n",
        "                                             blocks=layer_params[1],\n",
        "                                             stride=2)\n",
        "        self.layer3 = make_basic_block_layer(filter_num=256,\n",
        "                                             blocks=layer_params[2],\n",
        "                                             stride=2)\n",
        "        self.layer4 = make_basic_block_layer(filter_num=512,\n",
        "                                             blocks=layer_params[3],\n",
        "                                             stride=2)\n",
        "\n",
        "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES, activation=tf.keras.activations.softmax)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.layer1(x, training=training)\n",
        "        x = self.layer2(x, training=training)\n",
        "        x = self.layer3(x, training=training)\n",
        "        x = self.layer4(x, training=training)\n",
        "        x = self.avgpool(x)\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "class ResNetTypeII(tf.keras.Model):\n",
        "    def __init__(self, layer_params):\n",
        "        super(ResNetTypeII, self).__init__()\n",
        "        self.conv1 = tf.keras.layers.Conv2D(filters=64,\n",
        "                                            kernel_size=(7, 7),\n",
        "                                            strides=2,\n",
        "                                            padding=\"same\")\n",
        "        self.bn1 = tf.keras.layers.BatchNormalization()\n",
        "        self.pool1 = tf.keras.layers.MaxPool2D(pool_size=(3, 3),\n",
        "                                               strides=2,\n",
        "                                               padding=\"same\")\n",
        "\n",
        "        self.layer1 = make_bottleneck_layer(filter_num=64,\n",
        "                                            blocks=layer_params[0])\n",
        "        self.layer2 = make_bottleneck_layer(filter_num=128,\n",
        "                                            blocks=layer_params[1],\n",
        "                                            stride=2)\n",
        "        self.layer3 = make_bottleneck_layer(filter_num=256,\n",
        "                                            blocks=layer_params[2],\n",
        "                                            stride=2)\n",
        "        self.layer4 = make_bottleneck_layer(filter_num=512,\n",
        "                                            blocks=layer_params[3],\n",
        "                                            stride=2)\n",
        "\n",
        "        self.avgpool = tf.keras.layers.GlobalAveragePooling2D()\n",
        "        self.fc = tf.keras.layers.Dense(units=NUM_CLASSES, activation=tf.keras.activations.softmax)\n",
        "\n",
        "    def call(self, inputs, training=None, mask=None):\n",
        "        x = self.conv1(inputs)\n",
        "        x = self.bn1(x, training=training)\n",
        "        x = tf.nn.relu(x)\n",
        "        x = self.pool1(x)\n",
        "        x = self.layer1(x, training=training)\n",
        "        x = self.layer2(x, training=training)\n",
        "        x = self.layer3(x, training=training)\n",
        "        x = self.layer4(x, training=training)\n",
        "        x = self.avgpool(x)\n",
        "        output = self.fc(x)\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "def resnet_18():\n",
        "    return ResNetTypeI(layer_params=[2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def resnet_34():\n",
        "    return ResNetTypeI(layer_params=[3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def resnet_50():\n",
        "    return ResNetTypeII(layer_params=[3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def resnet_101():\n",
        "    return ResNetTypeII(layer_params=[3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def resnet_152():\n",
        "    return ResNetTypeII(layer_params=[3, 8, 36, 3])"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "URATMSMFWzZ7",
        "outputId": "e8359f73-0637-4ca4-8dd7-7af145cb3e5e"
      },
      "source": [
        "input_tensor = layers.Input(shape=(W, H, F), dtype='float32', name='input')\n",
        "\n",
        "# inputs, training=None, mask=None\n",
        "model = resnet_18()\n",
        "model.summary()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-2c7b698e7d85>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# inputs, training=None, mask=None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet_18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2374\u001b[0m     \"\"\"\n\u001b[1;32m   2375\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2376\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2377\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2378\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q20mF_Ztc8Rb"
      },
      "source": [
        "x = model.output\n",
        "x = layers.Dense(512)(x)\n",
        "x = layers.BatchNormalization()(x)\n",
        "x = layers.Activation('relu')(x)\n",
        "x = layers.Dense(Nout, activation='softmax', name='softmax')(x)\n",
        "model = Model(input_tensor, output_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JM1RVOI5W0-B"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "                 loss='categorical_crossentropy',\n",
        "                 metrics=['accuracy', precision, recall, f1score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsdOrxck-ngl"
      },
      "source": [
        "# Train 돌리기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clQfQ9r-g_WB"
      },
      "source": [
        "model = ResNet(W, H, F, Nout)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rTb9NdFn-EvX",
        "outputId": "79890cb0-6330-4efc-a765-7c512ea1b1d6"
      },
      "source": [
        "history = model.fit(\n",
        "  train_X, train_Y,\n",
        "  epochs=100,\n",
        "  batch_size=80,\n",
        "  validation_data=(test_X, test_Y),\n",
        "  shuffle=True,\n",
        ")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "11/11 [==============================] - 10s 631ms/step - loss: 7.0762 - accuracy: 0.0060 - val_loss: 5.8997 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "11/11 [==============================] - 6s 585ms/step - loss: 5.7182 - accuracy: 0.0224 - val_loss: 5.9108 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "11/11 [==============================] - 6s 588ms/step - loss: 5.1361 - accuracy: 0.0352 - val_loss: 5.9284 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "11/11 [==============================] - 6s 587ms/step - loss: 4.5134 - accuracy: 0.0722 - val_loss: 6.1592 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "11/11 [==============================] - 6s 580ms/step - loss: 3.9630 - accuracy: 0.1333 - val_loss: 6.7951 - val_accuracy: 0.0048\n",
            "Epoch 6/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 3.3137 - accuracy: 0.2489 - val_loss: 6.6084 - val_accuracy: 0.0048\n",
            "Epoch 7/100\n",
            "11/11 [==============================] - 6s 571ms/step - loss: 2.8262 - accuracy: 0.3604 - val_loss: 8.2219 - val_accuracy: 0.0048\n",
            "Epoch 8/100\n",
            "11/11 [==============================] - 6s 570ms/step - loss: 2.4641 - accuracy: 0.3931 - val_loss: 8.9101 - val_accuracy: 0.0048\n",
            "Epoch 9/100\n",
            "11/11 [==============================] - 6s 570ms/step - loss: 1.8856 - accuracy: 0.5165 - val_loss: 10.2709 - val_accuracy: 0.0048\n",
            "Epoch 10/100\n",
            "11/11 [==============================] - 6s 568ms/step - loss: 1.7415 - accuracy: 0.5518 - val_loss: 14.7627 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "11/11 [==============================] - 6s 571ms/step - loss: 1.4370 - accuracy: 0.6374 - val_loss: 19.2251 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "11/11 [==============================] - 6s 571ms/step - loss: 1.1607 - accuracy: 0.6781 - val_loss: 20.4350 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.8699 - accuracy: 0.7770 - val_loss: 23.6915 - val_accuracy: 0.0048\n",
            "Epoch 14/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.7297 - accuracy: 0.8181 - val_loss: 19.3931 - val_accuracy: 0.0048\n",
            "Epoch 15/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.5667 - accuracy: 0.8672 - val_loss: 21.4577 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "11/11 [==============================] - 6s 577ms/step - loss: 0.4218 - accuracy: 0.9035 - val_loss: 15.9990 - val_accuracy: 0.0048\n",
            "Epoch 17/100\n",
            "11/11 [==============================] - 6s 577ms/step - loss: 0.2760 - accuracy: 0.9429 - val_loss: 17.5079 - val_accuracy: 0.0095\n",
            "Epoch 18/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.2457 - accuracy: 0.9468 - val_loss: 19.4603 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "11/11 [==============================] - 6s 578ms/step - loss: 0.1650 - accuracy: 0.9580 - val_loss: 18.7722 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.1369 - accuracy: 0.9757 - val_loss: 19.3887 - val_accuracy: 0.0048\n",
            "Epoch 21/100\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.0957 - accuracy: 0.9844 - val_loss: 20.4552 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0772 - accuracy: 0.9861 - val_loss: 18.4915 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.0564 - accuracy: 0.9882 - val_loss: 19.2710 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "11/11 [==============================] - 6s 572ms/step - loss: 0.0458 - accuracy: 0.9958 - val_loss: 20.7024 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.0500 - accuracy: 0.9964 - val_loss: 20.2554 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0396 - accuracy: 0.9929 - val_loss: 21.8833 - val_accuracy: 0.0048\n",
            "Epoch 27/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0493 - accuracy: 0.9919 - val_loss: 22.2464 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0291 - accuracy: 0.9989 - val_loss: 21.3194 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0261 - accuracy: 0.9961 - val_loss: 19.1352 - val_accuracy: 0.0048\n",
            "Epoch 30/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0181 - accuracy: 0.9980 - val_loss: 19.4736 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0144 - accuracy: 0.9988 - val_loss: 21.0965 - val_accuracy: 0.0048\n",
            "Epoch 32/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0120 - accuracy: 1.0000 - val_loss: 20.4501 - val_accuracy: 0.0095\n",
            "Epoch 33/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0061 - accuracy: 1.0000 - val_loss: 19.4697 - val_accuracy: 0.0095\n",
            "Epoch 34/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 18.7110 - val_accuracy: 0.0095\n",
            "Epoch 35/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 17.9927 - val_accuracy: 0.0095\n",
            "Epoch 36/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 16.8976 - val_accuracy: 0.0095\n",
            "Epoch 37/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 16.6429 - val_accuracy: 0.0095\n",
            "Epoch 38/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 16.3439 - val_accuracy: 0.0095\n",
            "Epoch 39/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 15.8071 - val_accuracy: 0.0095\n",
            "Epoch 40/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 14.9786 - val_accuracy: 0.0095\n",
            "Epoch 41/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 13.8803 - val_accuracy: 0.0190\n",
            "Epoch 42/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 13.1256 - val_accuracy: 0.0238\n",
            "Epoch 43/100\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 12.2466 - val_accuracy: 0.0238\n",
            "Epoch 44/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 11.8268 - val_accuracy: 0.0286\n",
            "Epoch 45/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.0273 - accuracy: 0.9942 - val_loss: 9.7223 - val_accuracy: 0.0524\n",
            "Epoch 46/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0628 - accuracy: 0.9920 - val_loss: 10.0637 - val_accuracy: 0.0619\n",
            "Epoch 47/100\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.0413 - accuracy: 0.9951 - val_loss: 10.6480 - val_accuracy: 0.1048\n",
            "Epoch 48/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0746 - accuracy: 0.9899 - val_loss: 7.5805 - val_accuracy: 0.1095\n",
            "Epoch 49/100\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.0711 - accuracy: 0.9862 - val_loss: 5.9621 - val_accuracy: 0.1333\n",
            "Epoch 50/100\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.0706 - accuracy: 0.9884 - val_loss: 6.2137 - val_accuracy: 0.1810\n",
            "Epoch 51/100\n",
            "11/11 [==============================] - 6s 572ms/step - loss: 0.0388 - accuracy: 0.9948 - val_loss: 4.3545 - val_accuracy: 0.2667\n",
            "Epoch 52/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0646 - accuracy: 0.9845 - val_loss: 3.6974 - val_accuracy: 0.3714\n",
            "Epoch 53/100\n",
            "11/11 [==============================] - 6s 573ms/step - loss: 0.2022 - accuracy: 0.9676 - val_loss: 5.9613 - val_accuracy: 0.1714\n",
            "Epoch 54/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.1957 - accuracy: 0.9674 - val_loss: 6.8929 - val_accuracy: 0.2190\n",
            "Epoch 55/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.1926 - accuracy: 0.9454 - val_loss: 19.9494 - val_accuracy: 0.1762\n",
            "Epoch 56/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.2566 - accuracy: 0.9418 - val_loss: 10.4533 - val_accuracy: 0.2286\n",
            "Epoch 57/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.2387 - accuracy: 0.9524 - val_loss: 9.2979 - val_accuracy: 0.2095\n",
            "Epoch 58/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.1397 - accuracy: 0.9634 - val_loss: 68.2096 - val_accuracy: 0.1952\n",
            "Epoch 59/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.1697 - accuracy: 0.9674 - val_loss: 46.2027 - val_accuracy: 0.1143\n",
            "Epoch 60/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.2272 - accuracy: 0.9379 - val_loss: 54.8151 - val_accuracy: 0.0762\n",
            "Epoch 61/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.3200 - accuracy: 0.9060 - val_loss: 100.3254 - val_accuracy: 0.0333\n",
            "Epoch 62/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.1503 - accuracy: 0.9618 - val_loss: 44.7278 - val_accuracy: 0.0190\n",
            "Epoch 63/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.1372 - accuracy: 0.9594 - val_loss: 93.7896 - val_accuracy: 0.0238\n",
            "Epoch 64/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.1179 - accuracy: 0.9684 - val_loss: 21.3688 - val_accuracy: 0.1190\n",
            "Epoch 65/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0967 - accuracy: 0.9782 - val_loss: 16.3355 - val_accuracy: 0.1810\n",
            "Epoch 66/100\n",
            "11/11 [==============================] - 6s 577ms/step - loss: 0.0159 - accuracy: 0.9964 - val_loss: 16.4169 - val_accuracy: 0.2524\n",
            "Epoch 67/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0102 - accuracy: 0.9993 - val_loss: 5.1297 - val_accuracy: 0.4524\n",
            "Epoch 68/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0229 - accuracy: 0.9967 - val_loss: 3.4707 - val_accuracy: 0.5381\n",
            "Epoch 69/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 8.8858 - val_accuracy: 0.3190\n",
            "Epoch 70/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0138 - accuracy: 0.9951 - val_loss: 3.2386 - val_accuracy: 0.5476\n",
            "Epoch 71/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.0187 - accuracy: 0.9968 - val_loss: 2.7919 - val_accuracy: 0.5905\n",
            "Epoch 72/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0518 - accuracy: 0.9887 - val_loss: 3.4187 - val_accuracy: 0.5095\n",
            "Epoch 73/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0365 - accuracy: 0.9903 - val_loss: 2.6858 - val_accuracy: 0.5857\n",
            "Epoch 74/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.0138 - accuracy: 0.9968 - val_loss: 2.0152 - val_accuracy: 0.6667\n",
            "Epoch 75/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0042 - accuracy: 0.9991 - val_loss: 1.5423 - val_accuracy: 0.7476\n",
            "Epoch 76/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.0142 - accuracy: 0.9983 - val_loss: 1.1684 - val_accuracy: 0.8048\n",
            "Epoch 77/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0223 - accuracy: 0.9935 - val_loss: 2.3933 - val_accuracy: 0.5905\n",
            "Epoch 78/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0587 - accuracy: 0.9952 - val_loss: 8.6654 - val_accuracy: 0.3333\n",
            "Epoch 79/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0631 - accuracy: 0.9905 - val_loss: 4.0156 - val_accuracy: 0.4190\n",
            "Epoch 80/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0224 - accuracy: 0.9959 - val_loss: 2.8573 - val_accuracy: 0.5095\n",
            "Epoch 81/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0063 - accuracy: 0.9994 - val_loss: 2.1368 - val_accuracy: 0.6571\n",
            "Epoch 82/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0216 - accuracy: 0.9981 - val_loss: 1.5713 - val_accuracy: 0.7095\n",
            "Epoch 83/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0146 - accuracy: 0.9959 - val_loss: 2.1024 - val_accuracy: 0.7095\n",
            "Epoch 84/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0069 - accuracy: 0.9991 - val_loss: 2.2020 - val_accuracy: 0.7000\n",
            "Epoch 85/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0111 - accuracy: 0.9980 - val_loss: 2.8455 - val_accuracy: 0.6190\n",
            "Epoch 86/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0234 - accuracy: 0.9943 - val_loss: 1.7718 - val_accuracy: 0.7333\n",
            "Epoch 87/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0051 - accuracy: 0.9982 - val_loss: 1.6006 - val_accuracy: 0.7476\n",
            "Epoch 88/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 1.4979 - val_accuracy: 0.7571\n",
            "Epoch 89/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 1.2686 - val_accuracy: 0.7952\n",
            "Epoch 90/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 1.1573 - val_accuracy: 0.8286\n",
            "Epoch 91/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.0701 - val_accuracy: 0.8381\n",
            "Epoch 92/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 1.0636 - val_accuracy: 0.8286\n",
            "Epoch 93/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 8.8139e-04 - accuracy: 1.0000 - val_loss: 1.0592 - val_accuracy: 0.8429\n",
            "Epoch 94/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 5.7589e-04 - accuracy: 1.0000 - val_loss: 1.0422 - val_accuracy: 0.8476\n",
            "Epoch 95/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 5.0505e-04 - accuracy: 1.0000 - val_loss: 1.0156 - val_accuracy: 0.8571\n",
            "Epoch 96/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 6.9000e-04 - accuracy: 1.0000 - val_loss: 0.9947 - val_accuracy: 0.8524\n",
            "Epoch 97/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 7.0184e-04 - accuracy: 1.0000 - val_loss: 0.9736 - val_accuracy: 0.8571\n",
            "Epoch 98/100\n",
            "11/11 [==============================] - 6s 576ms/step - loss: 4.1022e-04 - accuracy: 1.0000 - val_loss: 0.9584 - val_accuracy: 0.8667\n",
            "Epoch 99/100\n",
            "11/11 [==============================] - 6s 574ms/step - loss: 5.4485e-04 - accuracy: 1.0000 - val_loss: 0.9312 - val_accuracy: 0.8667\n",
            "Epoch 100/100\n",
            "11/11 [==============================] - 6s 575ms/step - loss: 3.6217e-04 - accuracy: 1.0000 - val_loss: 0.9219 - val_accuracy: 0.8619\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPfssDKn-ydo"
      },
      "source": [
        "# Test 돌리기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_KDyOvy-Es8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f61b5beb-0f01-4f6a-bafd-bee2322e009f"
      },
      "source": [
        "loss, acc = model.evaluate(test_X, test_Y)\n",
        "\n",
        "print(\"\\nLoss: {}\\nAcc: {}\".format(loss, acc))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7/7 [==============================] - 1s 68ms/step - loss: 0.9219 - accuracy: 0.8619\n",
            "\n",
            "Loss: 0.921866774559021\n",
            "Acc: 0.8619047403335571\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GapYCQG5-EqX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "outputId": "6a53717a-2912-482f-a716-a1048bb63493"
      },
      "source": [
        "plot_loss(history)\n",
        "plt.show()\n",
        "plot_acc(history)\n",
        "plt.show()"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2m8obTXo_abF"
      },
      "source": [
        "# 교차 검증"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbBFKzalAQpv"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold, KFold"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BTsAlfJ_AMKI"
      },
      "source": [
        "## train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uLJtxk8fAOgZ",
        "outputId": "96046c2f-94ad-41c0-8e11-984d51b33597"
      },
      "source": [
        "# Define per-fold score containers\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "# cross validation\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "\n",
        "for train, test in kfold.split(train_X, train_Y):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = ResNet(W, H, F, Nout)\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Fit data to model\n",
        "  history = model.fit(train_X[train], train_Y[train], epochs=100,batch_size=100, verbose=0)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(train_X[test], train_Y[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')\n"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Score for fold 1: loss of 4.072591304779053; accuracy of 66.66666865348816%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Score for fold 2: loss of 6.06595516204834; accuracy of 50.59523582458496%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Score for fold 3: loss of 5.215511798858643; accuracy of 62.5%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Score for fold 4: loss of 5.347583770751953; accuracy of 65.47619104385376%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Score for fold 5: loss of 4.765905380249023; accuracy of 59.28143858909607%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 4.072591304779053 - Accuracy: 66.66666865348816%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 6.06595516204834 - Accuracy: 50.59523582458496%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 5.215511798858643 - Accuracy: 62.5%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 5.347583770751953 - Accuracy: 65.47619104385376%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 4.765905380249023 - Accuracy: 59.28143858909607%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 60.90390682220459 (+- 5.75436914464924)\n",
            "> Loss: 5.093509483337402\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AzxSUXyVANcF"
      },
      "source": [
        "## test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VnkYEVIH_ZyQ",
        "outputId": "fcaaab31-66d5-4f10-9c74-7f2c1e413812"
      },
      "source": [
        "# Define per-fold score containers\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "# cross validation\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=5, shuffle=True)\n",
        "# kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "\n",
        "for train, test in kfold.split(test_X, test_Y):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = model\n",
        "\n",
        "  # # Generate a print\n",
        "  # print('------------------------------------------------------------------------')\n",
        "  # print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # # Fit data to model\n",
        "  # history = model.fit(X_train[train], Y_train[train],\n",
        "  #                     batch_size=batch_size,\n",
        "  #                     epochs=epochs,\n",
        "  #                     verbose=0)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(test_X[test], test_Y[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')\n"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score for fold 1: loss of 4.87829065322876; accuracy of 59.52380895614624%\n",
            "Score for fold 2: loss of 5.174448490142822; accuracy of 54.76190447807312%\n",
            "Score for fold 3: loss of 3.2751901149749756; accuracy of 76.1904776096344%\n",
            "Score for fold 4: loss of 3.197998046875; accuracy of 61.90476417541504%\n",
            "Score for fold 5: loss of 4.115469932556152; accuracy of 64.28571343421936%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 4.87829065322876 - Accuracy: 59.52380895614624%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 5.174448490142822 - Accuracy: 54.76190447807312%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 3.2751901149749756 - Accuracy: 76.1904776096344%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 3.197998046875 - Accuracy: 61.90476417541504%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 4.115469932556152 - Accuracy: 64.28571343421936%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 63.33333373069763 (+- 7.158713085999601)\n",
            "> Loss: 4.128279447555542\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZkkvSW0r_F9z"
      },
      "source": [
        "# 결과 제출"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sillgepo-En3"
      },
      "source": [
        "import csv\n",
        "\n",
        "test_dir = './drive/MyDrive/02_face_test'\n",
        "file_list = os.listdir(test_dir)\n",
        "\n",
        "result = []\n",
        "\n",
        "for file in file_list:\n",
        "    name = file.split('.')[0]\n",
        "\n",
        "    data = cv2.imread(test_dir+'/'+file, 0)\n",
        "\n",
        "    data = cv2.resize(data, (W,H))\n",
        "    data = np.asarray(data)\n",
        "    data = data.astype('float32')\n",
        "\n",
        "    data = data.reshape(-1,W,H,1)\n",
        "    data = data / 255.\n",
        "\n",
        "    pred = np.argmax(model.predict(data), axis=1)\n",
        "\n",
        "    result.append([name, pred])\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBgmS2yZSj7X"
      },
      "source": [
        "with open('./drive/MyDrive/1871063_김서영_얼굴_2차_답안.csv', 'w', newline='') as f:\n",
        "  write = csv.writer(f)\n",
        "  write.writerow(['Image', 'Answer'])\n",
        "  write.writerows(result)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OAxkEekY4wXV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}